{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXYvzfMqHxND"
      },
      "outputs": [],
      "source": [
        "!pip install sentence_transformers\n",
        "!pip install pinecone-client\n",
        "!pip install protobuf\n",
        "!pip install transformers\n",
        "!pip install pandas\n",
        "!pip install sentencepiece "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_csScuNbz96",
        "outputId": "e002c404-b5e0-4109-f4bd-9d1041a237f8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/mamba/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm, trange\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pinecone import Pinecone, ServerlessSpec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "fe9c4fc0d290411da4337a78b117877e"
          ]
        },
        "id": "-ZCrmXksbyD3",
        "outputId": "52b132ad-be5d-42b7-ff29-1546fcc147c3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No sentence-transformers model found with name dangvantuan/sentence-camembert-large. Creating a new one with mean pooling.\n"
          ]
        }
      ],
      "source": [
        "model = SentenceTransformer(\"dangvantuan/sentence-camembert-large\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xEUlQcAxftn4"
      },
      "outputs": [],
      "source": [
        "pc = Pinecone(api_key=\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RD4vT-f1bZx1"
      },
      "source": [
        "# service public"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XwA1T0jRCCk4"
      },
      "outputs": [],
      "source": [
        "sentences = df['key_content'].values\n",
        "for i, line in enumerate(sentences):\n",
        "  if i % 100 == 0:\n",
        "    print(i)\n",
        "  sentences[i] = model.encode(line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZWEwD9wlejGd"
      },
      "outputs": [],
      "source": [
        "vectors = []\n",
        "\n",
        "for i, row in df.iterrows():\n",
        "    vectors.append({\n",
        "        \"id\": str(i),\n",
        "        \"values\": sentences[i],\n",
        "        \"metadata\": {\n",
        "            \"text\": row[\"key_content\"],\n",
        "            \"url\": row['url'],\n",
        "            \"title\": row[\"title\"]\n",
        "        }\n",
        "    })\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2a7oxAMyejC-"
      },
      "outputs": [],
      "source": [
        "import more_itertools\n",
        "\n",
        "# Function to split the vectors list into chunks of a specified size\n",
        "def chunks(lst, n):\n",
        "    for i in range(0, len(lst), n):\n",
        "        yield lst[i:i + n]\n",
        "\n",
        "# Create the index\n",
        "index = pc.Index(\"gouvx\")\n",
        "\n",
        "# Split the vectors into chunks of 100\n",
        "vector_chunks = chunks(vectors, 100)\n",
        "\n",
        "# Upsert each chunk\n",
        "for chunk in vector_chunks:\n",
        "    index.upsert(\n",
        "        vectors=chunk,\n",
        "        namespace=\"servicepublic\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_qiadQHei_r"
      },
      "outputs": [],
      "source": [
        "# update title field\n",
        "index = pc.Index(\"gouvx\")\n",
        "\n",
        "titles = df['title'].values\n",
        "for i, title in enumerate(titles):\n",
        "  if i % 100 == 0:\n",
        "    print(i)\n",
        "  index.update(namespace=\"servicepublic\", id=str(i), set_metadata={\"title\": title})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b8LfAPAbise"
      },
      "source": [
        "# Legifrance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Iojg6qCfei8P"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-07-03 09:01:03--  https://storage.googleapis.com/gouvx/legifrance/legifrance.csv\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.178.155, 142.250.179.123, 142.250.75.251, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.178.155|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 233803020 (223M) [text/csv]\n",
            "Saving to: ‘legifrance.csv’\n",
            "\n",
            "legifrance.csv      100%[===================>] 222.97M  68.4MB/s    in 3.4s    \n",
            "\n",
            "2024-07-03 09:01:07 (65.3 MB/s) - ‘legifrance.csv’ saved [233803020/233803020]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://storage.googleapis.com/gouvx/legifrance/legifrance.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ceZJWO2JboZX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"legifrance.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qih8wjKDbph9"
      },
      "outputs": [],
      "source": [
        "def recreate_title(proper_title):\n",
        "  title = proper_title.split(' > ')\n",
        "  title.reverse()\n",
        "  return \" - \".join(title) + \" - Légifrance\"\n",
        "\n",
        "def recreate_text(row):\n",
        "  return f\"\"\"{row['hierarchie']}\n",
        "{row['article_content']}\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "OKV_VnS-bqCN"
      },
      "outputs": [],
      "source": [
        "df_no_annex = df[~df[\"article_ref\"].str.contains(\"Annexe\")].copy()\n",
        "df_no_annex['title'] = df_no_annex['proper_title'].apply(lambda x: recreate_title(x))\n",
        "df_no_annex['text'] = df_no_annex.apply(lambda x: recreate_text(x), axis=1)\n",
        "df = df_no_annex[['title', 'text', 'url', 'domain', 'subdomain']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jbRJuVbHgICn",
        "outputId": "f2182814-ffb9-4f2b-a361-a70a632c1298"
      },
      "outputs": [],
      "source": [
        "df[\"token_len\"] = df[\"text\"].apply(lambda x: len(model.tokenizer.encode(x)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yLMPDYxAkj0R",
        "outputId": "4fd5ce79-0f70-45d1-c085-67cd2a63f360"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "150650 11605 139045\n",
            "0.07703285761699304 0.9229671423830069\n"
          ]
        }
      ],
      "source": [
        "df_large = df[df[\"token_len\"] > 512]\n",
        "df_small = df[df[\"token_len\"] <= 512]\n",
        "\n",
        "print(len(df), len(df_large), len(df_small))\n",
        "print(len(df_large)/len(df), len(df_small)/len(df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-_H-j0cf6li",
        "outputId": "b32b43ab-2bb1-48ea-f7a9-a97d30acc9cc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52507it [54:32, 13.49it/s]"
          ]
        }
      ],
      "source": [
        "import tqdm\n",
        "\n",
        "sentences = df_small['text'].values.copy()\n",
        "#for i, line in enumerate(sentences):\n",
        "for i, line in tqdm.tqdm(enumerate(sentences)):\n",
        "  sentences[i] = model.encode(line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7x6Z3ybPfgbI"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m vectors \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, row \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m      4\u001b[0m     vectors\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(i),\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m: sentences[i],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m         }\n\u001b[1;32m     12\u001b[0m     })\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ],
      "source": [
        "vectors = []\n",
        "\n",
        "for i, row in df.iterrows():\n",
        "    vectors.append({\n",
        "        \"id\": str(i),\n",
        "        \"values\": sentences[i],\n",
        "        \"metadata\": {\n",
        "            \"text\": row[\"text\"],\n",
        "            \"url\": row['url'],\n",
        "            \"title\": row[\"title\"]\n",
        "        }\n",
        "    })\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7fKBKqAjJdk"
      },
      "outputs": [],
      "source": [
        "import more_itertools\n",
        "\n",
        "# Function to split the vectors list into chunks of a specified size\n",
        "def chunks(lst, n):\n",
        "    for i in range(0, len(lst), n):\n",
        "        yield lst[i:i + n]\n",
        "\n",
        "# Create the index\n",
        "index = pc.Index(\"gouvx\")\n",
        "\n",
        "# Split the vectors into chunks of 100\n",
        "vector_chunks = chunks(vectors, 100)\n",
        "\n",
        "# Upsert each chunk\n",
        "for chunk in vector_chunks:\n",
        "    index.upsert(\n",
        "        vectors=chunk,\n",
        "        namespace=\"legifrance\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "RD4vT-f1bZx1"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
